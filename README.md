This project aims at creating a Kafka producer consumer message passing stream, where consumers subscribe to topics generated by the producer and process the data retrieved.
There are 3 topics generated by the producer and 3 consumers.
### Project Summary: Kafka-based Social Media Data Processor

This project consists of a Kafka-based system for processing social media data, divided into three main components: a producer and three different consumers. Each component has a specific role in processing and analyzing the data. 

#### Components Overview:

1. **Producer (`producer.py`)**
2. **Consumer 1 (`consumer1.py`)**
3. **Consumer 2 (`consumer2.py`)**
4. **Consumer 3 (`consumer3.py`)**

### Producer

The `producer.py` script reads from standard input, processes the input data, and sends it to the appropriate Kafka topics based on the content. It is designed to work with three Kafka topics specified as command-line arguments.


### Consumer 1

The `consumer1.py` script reads messages from a specified Kafka topic and processes the data to store user-specific information in a dictionary. It then outputs this data in a structured JSON format.


### Consumer 2

The `consumer2.py` script reads messages from another Kafka topic, processes actions (like, comment, share), and calculates a score based on the actions for each user. It outputs this data in JSON format.



### Consumer 3

The `consumer3.py` script reads messages from another Kafka topic and processes them to store user-specific actions. It calculates a composite score for each user based on likes, comments, and shares, and outputs this data in JSON format.

